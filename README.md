# RFormer
Official Repository for the NeurIPS 2024 paper *Rough Transformers: Lightweight and Continuous Time Series Modelling through Signature Patching*

(Note: Description of how to run will come soon. The code will also undergo some refactoring in the near future.)

Please, if you use this code, cite the `published paper in Proceedings of NeurIPS 2024<https://arxiv.org/abs/2405.20799>`_:

.. code-block:: bash

   @misc{morenopino2022pyhhmm,
      title={PyHHMM: A Python Library for Heterogeneous Hidden Markov Models}, 
      author={Fernando Moreno-Pino and Emese Sükei and Pablo M. Olmos and Antonio Artés-Rodríguez},
      year={2022},
      eprint={2201.06968},
      archivePrefix={arXiv},
      primaryClass={cs.MS}
   }


   @inproceedings{morenorough,
    title={Rough Transformers: Lightweight and Continuous Time Series Modelling through Signature Patching},
    author={Moreno-Pino, Fernando and Arroyo, Alvaro and Waldon, Harrison and Dong, Xiaowen and Cartea, Alvaro},
    booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems}
  }   
